package com.cummins.project734.luceneentity;


import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.io.Reader;
import java.util.Date;
import java.util.Scanner;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.FieldType;
import org.apache.lucene.document.StringField;
import org.apache.lucene.document.TextField;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.util.Version;



public class IndexBuilder {


	public void buildIndex(String fileName, String no_fields, String delimiter) throws IOException{
		//fileDir is the directory that contains the text files to be indexed
		File   fileDir  = new File(fileName);
		
		String colDelim = ";";


		//indexDir is the directory that hosts Lucene's index files
		Directory indexDir = null;
		try {
			indexDir = FSDirectory.open(new File( "C:\\luceneIndex" ));
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		//File  indexDir = new File("C:\\luceneIndex");
		Analyzer luceneAnalyzer = new StandardAnalyzer(Version.LUCENE_40);
		IndexWriterConfig conf = new IndexWriterConfig(null, luceneAnalyzer).setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);
		IndexWriter indexWriter = new IndexWriter(indexDir,conf);
		File[] textFiles  = fileDir.listFiles();
		System.out.println("Files: "+fileDir.getName());
		System.out.println("Files: "+fileDir.getName()+ " length: "+fileDir.exists());
		long startTime = new Date().getTime();

		//Add documents to the index
		for(int i = 0; i < textFiles.length; i++){
			System.out.println("Loop: "+i);
			if(textFiles[i].isFile() && textFiles[i].getName().endsWith(".txt")){
				System.out.println("File " + textFiles[i].getCanonicalPath() 
						+ " is being indexed");
				String file = textFiles[i].toString();

				Scanner scanner = new Scanner(new File(file));

				String line = "";
				scanner.useDelimiter(delimiter);
				while(scanner.hasNext()){


					line = scanner.next();
					System.out.println("Record: "+line);

					String[] tokenizedLine = line.split(colDelim);

					Document document = new Document();
					FieldType ft  = new FieldType();

					ft.setIndexed(true);
					//ft.tokenized();
					ft.setTokenized(true);
					for(int j=0;j<tokenizedLine.length;j++){
						System.out.println("Field after tokenization: "+tokenizedLine[j]);
						document.add(new Field("Field "+j, tokenizedLine[j], ft));
						
					}
					document.add(new StringField("path",textFiles[i].getCanonicalPath(), Field.Store.YES));
					System.out.println(""+document);
					indexWriter.addDocument(document);
				}



				// indexWriter.optimize();
				indexWriter.close();
				long endTime = new Date().getTime();

				System.out.println("It took " + (endTime - startTime) 
						+ " milliseconds to create an index for the files in the directory "
						+ fileDir.getPath());
			}
		}
	}

	
	public void buildIndex(String fileName, String no_fields, Integer[] fieldLen) throws IOException {
		// TODO Auto-generated method stub
		File   fileDir  = new File(fileName);




		//indexDir is the directory that hosts Lucene's index files
		Directory indexDir = null;
		try {
			indexDir = FSDirectory.open(new File( "C:\\luceneIndex" ));
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		//File  indexDir = new File("C:\\luceneIndex");
		Analyzer luceneAnalyzer = new StandardAnalyzer(Version.LUCENE_40);
		IndexWriterConfig conf = new IndexWriterConfig(null, luceneAnalyzer).setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);
		IndexWriter indexWriter = new IndexWriter(indexDir,conf);


		File[] textFiles  = fileDir.listFiles();

		System.out.println("Files: "+fileDir.getName());
		System.out.println("Files: "+fileDir.getName()+ " length: "+fileDir.exists());
		long startTime = new Date().getTime();

		//Add documents to the index
		for(int i = 0; i < textFiles.length; i++){
			System.out.println("Loop: "+i);
			if(textFiles[i].isFile() && textFiles[i].getName().endsWith(".txt")){
				System.out.println("File " + textFiles[i].getCanonicalPath() 
						+ " is being indexed");
				String file = textFiles[i].toString();
				Reader textReader = new FileReader(textFiles[i]);
				BufferedReader br = new BufferedReader(textReader);
				String line = "";
				int totalLen = 0;
				int k=0;
				int j=1;
				while(!br.readLine().isEmpty()){

					String[] tokenizedLine = {""};
					line = br.readLine();
					//	System.out.println("Array: 0:"+fieldLen[0]+" 1:"+fieldLen[1]+" 2:"+fieldLen[2]+" 3: "+fieldLen[3]+" 4:"+fieldLen[4] );
					System.out.println("Record: "+line+" Length: "+line.length());

					for(j=1;j<fieldLen.length;j++){
						String temp = line.substring(totalLen, totalLen+fieldLen[j]);
						totalLen = totalLen+fieldLen[j];
						tokenizedLine[k] = temp;
						System.out.println("Tokenized line,location "+k+": "+tokenizedLine[k]);
						temp="";
						k++;
					}

					Document document = new Document();
					FieldType ft  = new FieldType();

					ft.setIndexed(true);
					//ft.tokenized();
					ft.setTokenized(true);
					for(j=0;j<tokenizedLine.length;j++){
						System.out.println("Field after tokenization: "+tokenizedLine[j]);
						document.add(new Field("Field "+j, tokenizedLine[j], ft));

					}
					document.add(new StringField("path",textFiles[i].getCanonicalPath(), Field.Store.YES));
					System.out.println(""+document);
					indexWriter.addDocument(document);
				}



				// indexWriter.optimize();
				indexWriter.close();
				long endTime = new Date().getTime();

				System.out.println("It took " + (endTime - startTime) 
						+ " milliseconds to create an index for the files in the directory "
						+ fileDir.getPath());
			}
		}

	}
}